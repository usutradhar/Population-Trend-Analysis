{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26883c12-315a-42fc-8025-c89ca029fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install packagename\n",
    "# importing modules\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from os import chdir as cd\n",
    "import time\n",
    "import fiona\n",
    "from datetime import date\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72b7714c-f212-4321-b074-637e1b2b318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv\n",
    "df_main = pd.read_csv(r'D:\\Work\\Box Sync\\Trends_all states\\Output from Analysis\\df_attributes.csv', \n",
    "                      dtype = {'GEOID':str}, index_col = 0)\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76b31ada-33f3-4d47-ae5e-93db884a3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data types\n",
    "# df_main.shape, df_main.dtypes, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb2d0cbf-8340-4aae-ba1d-c0195b827c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REGION\n",
       "South                    10504\n",
       "Midwest                  10213\n",
       "West                      6063\n",
       "Northeast                 4816\n",
       "Outside Contiguous US      292\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main['REGION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ba380-3438-44d1-99e3-55a2d3c9453d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83ad16f9-8b28-4049-beca-395d153fd852",
   "metadata": {},
   "source": [
    "# Convert continuous to categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e18dd4e-2f5b-41ea-b448-69beedab05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_main.copy()\n",
    "\n",
    "# ======== To fill null values for the binned column ========\n",
    " \n",
    "def replace_nan_by_noData(dataframe, column_name):\n",
    "    # Creating a Series\n",
    "    df_to_series = pd.Series(dataframe[column_name],dtype='category')\n",
    "    # Filling NaN values in this series\n",
    "    added_no_data = df_to_series.cat.add_categories(\"no data\").fillna(\"no data\")\n",
    "    return added_no_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "813955ce-ac33-4a8d-ae7f-6eb859ee41e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:---\n",
      "3312\n"
     ]
    }
   ],
   "source": [
    "# Binning continuous variable to categorical for to plot parallel category plot and easier visibility\n",
    "# for Binning, we are using tax brackets from 2023 IRS data\n",
    "# Source: https://www.irs.gov/newsroom/irs-provides-tax-inflation-adjustments-for-tax-year-2023\n",
    "df['hh_income_by_taxRate'] = pd.cut(df['median_income'], \n",
    "                                    [0, 15700, 59850, 95350, 182000, 231250, 1000000],\n",
    "                                    labels=[\"10%\", \"12%\", \"22%\", \"24%\", \"32%\", \"35%+\"])\n",
    "print('Null values:---')\n",
    "print(df['hh_income_by_taxRate'].isnull().sum())\n",
    "\n",
    "df['hhincome by taxRate'] = replace_nan_by_noData(df, 'hh_income_by_taxRate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85809f34-667a-4302-a18f-0f6a948972f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning continuous variable to categorical for to plot parallel category plot and easier visibility\n",
    "# for Binning, we are using tax brackets from 2023 IRS data\n",
    "df['One or fewer vehicles'] = pd.cut(df['veh_<=_1'], [-1, 10, 20, 30, 40, 50, 100],\n",
    "                            labels=[\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40-50\", \"50+\"])\n",
    "\n",
    "df['One or fewer vehicles'] = replace_nan_by_noData(df, 'One or fewer vehicles')\n",
    "\n",
    "df['Two or more vehicles'] = pd.cut(df['veh_2_or+'], [-1, 10, 20, 30, 40, 50, 105],\n",
    "                            labels=[\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40-50\", \"50+\"])\n",
    "\n",
    "df['Two or more vehicles'] = replace_nan_by_noData(df, 'Two or more vehicles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79712ece-ae89-4440-8a79-3c16c46eb31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REGION\n",
       "South                    10504\n",
       "Midwest                  10213\n",
       "West                      6063\n",
       "Northeast                 4816\n",
       "Outside Contiguous US      292\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['REGION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "270d47b1-4ec9-4809-a14c-bb75c98f469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities in Region 5: Outside Contiguous US \n",
      "STATEFP\n",
      "72    292\n",
      "Name: count, dtype: int64\n",
      "Remaining cities after excluding Region 5: (31596, 40)\n"
     ]
    }
   ],
   "source": [
    "print('Cities in Region 5: Outside Contiguous US ')\n",
    "print(df[df['REGION'] == 'Outside Contiguous US']['STATEFP'].value_counts())\n",
    "\n",
    "# Excluding cities in Region 5 since that is not available in forecasted values\n",
    "df = df[df['REGION'] != 'Outside Contiguous US']\n",
    "print(f'Remaining cities after excluding Region 5: {df.shape}')\n",
    "\n",
    "\n",
    "# df = df.sort_values(by = ['REGION', ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae68bd5-c8cb-4995-9609-7d7082ac610d",
   "metadata": {},
   "source": [
    "# hh vehicle ownership vs Population trend by REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "961fabe7-c680-4bef-93aa-f7a2a9a9e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_col =  'future trend from SSP 4'\n",
    "\n",
    "df['REGION_NO'] = df['REGION'].map({'Northeast': 1, 'Midwest': 2,'West': 3, 'South': 4})\n",
    "# Create dimensions\n",
    "region_dim = go.parcats.Dimension(\n",
    "    values=df[\"REGION\"], label=\"REGION\",\n",
    "    categoryarray=['Northeast', 'Midwest','West', 'South'],\n",
    ")\n",
    "\n",
    "veh_1_dim = go.parcats.Dimension(\n",
    "    values=df['One or fewer vehicles'], categoryorder=\"category ascending\", label= '% pop with One/fewer vehicles'\n",
    ")\n",
    "\n",
    "veh_2_dim = go.parcats.Dimension(\n",
    "    values=df['Two or more vehicles'], categoryorder=\"category ascending\", label= '% pop with Two/more vehicles'\n",
    ")\n",
    "\n",
    "city_dim = go.parcats.Dimension(values=df[\"city type\"], label=\"city type\",\n",
    "                               categoryarray=['urban', 'suburban' , 'periurban', 'rural', 'not enough data'],\n",
    "                               ticktext=['urban', 'suburban' , 'periurban', 'rural', 'not enough data'])\n",
    "\n",
    "future_trend_dim = go.parcats.Dimension(\n",
    "    values=df[trend_col], label=trend_col,\n",
    "    categoryarray = ['increasing', 'no trend' , 'decreasing'],\n",
    ")\n",
    "\n",
    "\n",
    "# Build colorscale\n",
    "color = [x for x in df['REGION_NO']]\n",
    "colorscale = ['#8C564B', '#9467BD', '#F7B6D2', '#DBDB8D'] # ['darkseagreen', 'orchid', 'plum', 'lightsteelblue'] # ['goldenrod','forestgreen','lightblue', 'slateblue', 'darkmagenta']\n",
    "# create figure object\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Parcats(\n",
    "            dimensions=[\n",
    "                region_dim,\n",
    "                veh_1_dim,\n",
    "                veh_2_dim,\n",
    "                future_trend_dim,\n",
    "                city_dim,\n",
    "            ],\n",
    "            line={\"color\": color, \"colorscale\": colorscale, 'shape': 'hspline'},\n",
    "            hoveron=\"color\",\n",
    "            hoverinfo=\"count + probability\",\n",
    "            labelfont={\"size\": 10,\"family\": \"arial\"},\n",
    "            tickfont={\"size\":  10,\"family\": \"arial\"},\n",
    "            arrangement=\"freeform\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=300,\n",
    "    width=700,\n",
    "    font=dict(size=10, ),\n",
    "    margin=dict(l=10, r=18, t=15, b=12))\n",
    "\n",
    "fig.write_image(r\"D:\\Work\\Box Sync\\NC Figures\\\\veh_ownership_\" + str(trend_col) + \".png\", scale=4, engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8fde4d-0ba2-4e08-b635-5c65d61888ab",
   "metadata": {},
   "source": [
    "# Income vs Population trend by REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa90a82d-47ae-4469-b7f3-fab0861d24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating parallel categores chart\n",
    "\n",
    "trend_col =  'future trend from SSP 4'\n",
    "df['REGION_NO'] = df['REGION'].map({'Northeast': 1, 'Midwest': 2,'West': 3, 'South': 4})\n",
    "# Create dimensions\n",
    "# stalk-shape\n",
    "income_dim = go.parcats.Dimension(\n",
    "    values=df['hhincome by taxRate'], categoryorder=\"category ascending\", label= 'hhincome by taxRate'\n",
    ")\n",
    "# stalk-root\n",
    "city_dim = go.parcats.Dimension(values=df[\"city type\"], label=\"city type\",\n",
    "                               categoryarray=['urban', 'suburban' , 'periurban', 'rural', 'not enough data'],\n",
    "    ticktext=['urban', 'suburban' , 'periurban', 'rural', 'not enough data'])\n",
    "# stalk-surface-above-ring\n",
    "future_trend_dim = go.parcats.Dimension(\n",
    "    values=df[trend_col], label=trend_col,\n",
    "    categoryarray = ['increasing', 'no trend' , 'decreasing'],\n",
    ")\n",
    "# stalk-surface-below-ring\n",
    "region_dim = go.parcats.Dimension(\n",
    "    values=df[\"REGION\"], label=\"REGION\",\n",
    "    categoryarray=['Northeast', 'Midwest','West', 'South'],\n",
    ")\n",
    "\n",
    "# Build colorscale\n",
    "color = [x for x in df['REGION_NO']]\n",
    "colorscale = ['#8C564B', '#9467BD', '#F7B6D2', '#DBDB8D'] # ['darkseagreen', 'orchid', 'plum', 'lightsteelblue'] # ['goldenrod','forestgreen','lightblue', 'slateblue', 'darkmagenta']\n",
    "# create figure object\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Parcats(\n",
    "            dimensions=[\n",
    "                region_dim,\n",
    "                # city_dim,\n",
    "                income_dim,\n",
    "                future_trend_dim,\n",
    "                city_dim,\n",
    "            ],\n",
    "            line={\"color\": color, \"colorscale\": colorscale, 'shape': 'hspline',},\n",
    "            hoveron=\"color\",\n",
    "            hoverinfo=\"count + probability\",\n",
    "            labelfont={\"size\": 10,\"family\": \"arial\"},\n",
    "            tickfont={\"size\":  10,\"family\": \"arial\"},\n",
    "            arrangement=\"freeform\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=300,\n",
    "    width=600,\n",
    "    font=dict(size=10, ),\n",
    "    margin=dict(l=10, r=18, t=15, b=12))\n",
    "\n",
    "fig.write_image(r\"D:\\Work\\Box Sync\\NC Figures\\median_income_\" + str(trend_col) + \".png\", engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea8e3fb-584c-4464-86b2-d08eb9e8f03f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33396574-911f-4f7b-b384-bf3d0b8ee3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Build parcats dimensions\n",
    "# # categorical_dimensions = ['REGION', 'One or fewer vehicles', 'Two or more vehicles','city type', 'future trend from SSP 4', ];\n",
    "\n",
    "# # dimensions = [dict(values=df[label], label=label) for label in categorical_dimensions]\n",
    "# trend_col =  'future trend from SSP 2'\n",
    "# df['REGION_NO'] = df['REGION'].map({'Northeast': 1, 'Midwest': 2,'West': 3, 'South': 4})\n",
    "# # Build colorscale\n",
    "# color = [x for x in df['REGION_NO']]\n",
    "# colorscale = ['#8C564B', '#9467BD', '#F7B6D2', '#DBDB8D'] # ['goldenrod','forestgreen','slateblue', 'darkmagenta',]\n",
    "\n",
    "# # Build figure as FigureWidget\n",
    "# fig = go.Figure(go.Parcats(\n",
    "#         # domain={'y': [0, 0.4]}, \n",
    "#         dimensions=dimensions,\n",
    "#         line={'colorscale': colorscale,\n",
    "#               'color': color, \n",
    "#               'shape': 'hspline'}))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     height=600,\n",
    "#     width=1000,\n",
    "#         # dragmode='lasso', hovermode='closest',\n",
    "#         font=dict(\n",
    "#         # family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         # color=\"RebeccaPurple\"\n",
    "#     ))\n",
    "\n",
    "# fig\n",
    "# # fig.write_html(r'D:\\Work\\Box Sync\\PhD_Work_Uttara\\NC_submission_shared\\Final_submission\\Final_plots\\veh_ownership_populationTrend.html')\n",
    "# # fig.write_image(r'D:\\Work\\Box Sync\\Depop Paper NC\\Paper Draft NC\\Figures\\vehicle_ownership_SSP2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0136b20b-0678-4917-90c6-ad8ffc18388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Build parcats dimensions\n",
    "# categorical_dimensions = ['REGION','hhincome by taxRate', 'future trend from SSP 4', 'city type',];\n",
    "\n",
    "# dimensions = [dict(values=df[label], label=label) for label in categorical_dimensions]\n",
    "\n",
    "# # Build colorscale\n",
    "# color = [x for x in df['REGION_NO']]\n",
    "# colorscale = ['#8C564B', '#9467BD', '#F7B6D2', '#DBDB8D'] # ['darkseagreen', 'orchid', 'plum', 'lightsteelblue'] # ['goldenrod','forestgreen','lightblue', 'slateblue', 'darkmagenta']\n",
    "\n",
    "# # Build figure as FigureWidget\n",
    "# fig = go.Figure(go.Parcats(\n",
    "#         # domain={'y': [0, 0.4]}, \n",
    "#         dimensions=dimensions,\n",
    "#         line={'colorscale': colorscale,\n",
    "#               'color': color, \n",
    "#               'shape': 'hspline'}))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     height=400,\n",
    "#     width=1000,\n",
    "#         # dragmode='lasso', hovermode='closest',\n",
    "#         font=dict(\n",
    "#         # family=\"Courier New, monospace\",\n",
    "#         size=10,\n",
    "#         # color=\"RebeccaPurple\"\n",
    "#     ))\n",
    "\n",
    "# fig\n",
    "# fig.update_traces(dimensions=[{\"categoryorder\": \"category ascending\"} for _ in dimensions])\n",
    "\n",
    "# # fig.write_html(r'D:\\Work\\Box Sync\\PhD_Work_Uttara\\NC_submission_shared\\Final_submission\\Final_plots\\median_income_populationTrend.html')\n",
    "# # fig.write_image(r'D:\\Work\\Box Sync\\Depop Paper NC\\Paper Draft NC\\Figures\\median_income_SSP2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14b1273-21de-4c37-a149-70dfac6daf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # for parallet plot the first column needs to be numeric values\n",
    "# for i in range(len(df)):\n",
    "#     # print(i)\n",
    "#     if df.loc[i,'REGION'] == 'Northeast':\n",
    "#         df.loc[i,'REGION_NO'] = 1\n",
    "#     elif df.loc[i,'REGION'] == 'Midwest':\n",
    "#         df.loc[i,'REGION_NO'] = 2 \n",
    "#     elif df.loc[i,'REGION'] == 'South':\n",
    "#         df.loc[i,'REGION_NO'] = 3\n",
    "#     elif df.loc[i,'REGION'] == 'West':\n",
    "#         df.loc[i,'REGION_NO'] = 4\n",
    "#     else:\n",
    "#         df.loc[i,'REGION_NO'] = 5  \n",
    "\n",
    "# # If city type is the first variable, then---\n",
    "# for i in range(len(df)):\n",
    "#     # print(i)\n",
    "#     if df.loc[i,'city type'] == 'urban':\n",
    "#         df.loc[i,'city type'] = 1\n",
    "#     elif df.loc[i,'city type'] == 'suburban':\n",
    "#         df.loc[i,'city type'] = 2\n",
    "#     elif df.loc[i,'city type'] == 'periurban':\n",
    "#         df.loc[i,'city type'] = 3\n",
    "#     elif df.loc[i,'city type'] == 'rural':\n",
    "#         df.loc[i,'city type'] = 4\n",
    "#     else:\n",
    "#         df.loc[i,'city type'] = 5  \n",
    "\n",
    "# # If future trend is the first variable, then---\n",
    "# for i in range(len(df)):\n",
    "#     # print(i)\n",
    "#     if df.loc[i,'future trend from SSP 2'] == 'increasing':\n",
    "#         df.loc[i,'future trend from SSP 2'] = 1\n",
    "#     elif df.loc[i,'future trend from SSP 2'] == 'no trend':\n",
    "#         df.loc[i,'future trend from SSP 2'] = 2\n",
    "#     elif df.loc[i,'future trend from SSP 2'] == 'decreasing':\n",
    "#         df.loc[i,'future trend from SSP 2'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fde454-6455-4932-b338-4f95ec8e6e7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Check p-values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3f055b4-055b-4f4c-85bc-b493a26bc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # print(i)\n",
    "    if df.loc[i,'future trend from SSP 2'] == 'increasing':\n",
    "        df.loc[i,'future trend from SSP 2'] = 1\n",
    "    elif df.loc[i,'future trend from SSP 2'] == 'no trend':\n",
    "        df.loc[i,'future trend from SSP 2'] = 2\n",
    "    elif df.loc[i,'future trend from SSP 2'] == 'decreasing':\n",
    "        df.loc[i,'future trend from SSP 2'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "800cd573-085e-49c3-a6a1-c2850021fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_south = df[df['REGION'] == 'South'].reset_index(drop = True)[['future trend from SSP 2', 'median_income', 'hh_income_by_taxRate']].dropna()\n",
    "df_west = df[df['REGION'] == 'West'].reset_index(drop = True)[['future trend from SSP 2', 'median_income', 'hh_income_by_taxRate']].dropna()\n",
    "df_midwest = df[df['REGION'] == 'Midwest'].reset_index(drop = True)[['future trend from SSP 2', 'median_income', 'hh_income_by_taxRate']].dropna()\n",
    "df_northeast = df[df['REGION'] == 'Northeast'].reset_index(drop = True)[['future trend from SSP 2', 'median_income', 'hh_income_by_taxRate']].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d260426-6642-4638-8976-f6b5e7a2f8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh_income_by_taxRate     10%   12%   22%  24%  32%  35%+\n",
      "future trend from SSP 2                                 \n",
      "1                         11  2279  1447  659   53    31\n",
      "2                          7   608   172   32    1     0\n",
      "3                         39  3406   477  101    1     1\n",
      "The P-Value of the ChiSq Test is: 3.0409471316678297e-263\n",
      "\n",
      "\n",
      "----Statistics from one way ANOVA----\n",
      "F-Statistic: 818.4671241829363\n",
      "P-value: 0.0\n",
      "\n",
      "\n",
      "----Statistics from Kruskal-Wallis----\n",
      "H-Statistic: 1808.874071342676\n",
      "P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Cross tabulation \n",
    "CrosstabResult=pd.crosstab(index=df_south['future trend from SSP 2'],columns=df_south['hh_income_by_taxRate'])\n",
    "print(CrosstabResult)\n",
    "# importing the required function\n",
    "from scipy.stats import chi2_contingency\n",
    "# Performing Chi-sq test\n",
    "ChiSqResult = chi2_contingency(CrosstabResult)\n",
    "# P-Value is the Probability of H0 being True\n",
    "# If P-Value&gt;0.05 then only we Accept the assumption(H0)\n",
    "print('The P-Value of the ChiSq Test is:', ChiSqResult[1])\n",
    "print('\\n')\n",
    "from scipy.stats import f_oneway\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(*[group['median_income'].values for name, group in df_south.groupby(\"future trend from SSP 2\")])\n",
    "# Print results\n",
    "print('----Statistics from one way ANOVA----')\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print('\\n')\n",
    "# Kuruskul Wallis Test\n",
    "from scipy.stats import kruskal\n",
    "#perform Kruskal-Wallis Test \n",
    "H_statistic, p_value = kruskal(*[group[\"median_income\"].values for name, group in df_south.groupby(\"future trend from SSP 2\")])\n",
    "print('----Statistics from Kruskal-Wallis----')\n",
    "print(\"H-Statistic:\", H_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad19977c-214d-4e11-b193-395690dbc340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh_income_by_taxRate     10%   12%   22%  24%  32%  35%+\n",
      "future trend from SSP 2                                 \n",
      "1                         11  1049  1186  648   42    32\n",
      "2                          1   365   184   64    1     1\n",
      "3                         16  1038   326   56    2     0\n",
      "The P-Value of the ChiSq Test is: 1.9543788075541208e-131\n",
      "\n",
      "\n",
      "----Statistics from one way ANOVA----\n",
      "F-Statistic: 329.60747344330446\n",
      "P-value: 3.1935135789049384e-135\n",
      "\n",
      "\n",
      "----Statistics from Kruskal-Wallis----\n",
      "H-Statistic: 757.8376529163778\n",
      "P-value: 2.739331426855337e-165\n"
     ]
    }
   ],
   "source": [
    "# Cross tabulation \n",
    "CrosstabResult=pd.crosstab(index=df_west['future trend from SSP 2'],columns=df_west['hh_income_by_taxRate'])\n",
    "print(CrosstabResult)\n",
    "# importing the required function\n",
    "from scipy.stats import chi2_contingency\n",
    "# Performing Chi-sq test\n",
    "ChiSqResult = chi2_contingency(CrosstabResult)\n",
    "# P-Value is the Probability of H0 being True\n",
    "# If P-Value&gt;0.05 then only we Accept the assumption(H0)\n",
    "print('The P-Value of the ChiSq Test is:', ChiSqResult[1])\n",
    "print('\\n')\n",
    "from scipy.stats import f_oneway\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(*[group['median_income'].values for name, group in df_west.groupby(\"future trend from SSP 2\")])\n",
    "# Print results\n",
    "print('----Statistics from one way ANOVA----')\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print('\\n')\n",
    "# Kuruskul Wallis Test\n",
    "from scipy.stats import kruskal\n",
    "#perform Kruskal-Wallis Test \n",
    "H_statistic, p_value = kruskal(*[group[\"median_income\"].values for name, group in df_west.groupby(\"future trend from SSP 2\")])\n",
    "print('----Statistics from Kruskal-Wallis----')\n",
    "print(\"H-Statistic:\", H_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "036af1c1-e53e-4c2f-935f-45e5d231b619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh_income_by_taxRate     10%   12%  22%  24%  32%  35%+\n",
      "future trend from SSP 2                                \n",
      "1                          0   325  644  542   47    31\n",
      "2                          1   189  211   97    6     0\n",
      "3                          4  1384  771  267   10     8\n",
      "The P-Value of the ChiSq Test is: 4.116473674286151e-138\n",
      "\n",
      "\n",
      "----Statistics from one way ANOVA----\n",
      "F-Statistic: 368.04642682253746\n",
      "P-value: 7.613507348138938e-149\n",
      "\n",
      "\n",
      "----Statistics from Kruskal-Wallis----\n",
      "H-Statistic: 706.4916301062717\n",
      "P-value: 3.866266326937705e-154\n"
     ]
    }
   ],
   "source": [
    "# Cross tabulation \n",
    "CrosstabResult=pd.crosstab(index=df_northeast['future trend from SSP 2'],columns=df_northeast['hh_income_by_taxRate'])\n",
    "print(CrosstabResult)\n",
    "# importing the required function\n",
    "from scipy.stats import chi2_contingency\n",
    "# Performing Chi-sq test\n",
    "ChiSqResult = chi2_contingency(CrosstabResult)\n",
    "# P-Value is the Probability of H0 being True\n",
    "# If P-Value&gt;0.05 then only we Accept the assumption(H0)\n",
    "print('The P-Value of the ChiSq Test is:', ChiSqResult[1])\n",
    "print('\\n')\n",
    "from scipy.stats import f_oneway\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(*[group['median_income'].values for name, group in df_northeast.groupby(\"future trend from SSP 2\")])\n",
    "# Print results\n",
    "print('----Statistics from one way ANOVA----')\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print('\\n')\n",
    "# Kuruskul Wallis Test\n",
    "from scipy.stats import kruskal\n",
    "#perform Kruskal-Wallis Test \n",
    "H_statistic, p_value = kruskal(*[group[\"median_income\"].values for name, group in df_northeast.groupby(\"future trend from SSP 2\")])\n",
    "print('----Statistics from Kruskal-Wallis----')\n",
    "print(\"H-Statistic:\", H_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09a2addc-43e5-4db4-9dfc-1821a131c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh_income_by_taxRate     10%   12%   22%  24%  32%  35%+\n",
      "future trend from SSP 2                                 \n",
      "1                          7  1216  1036  301   16    14\n",
      "2                          4   517   292   73    1     1\n",
      "3                         20  4363  1384  167   11     3\n",
      "The P-Value of the ChiSq Test is: 3.821526111351939e-138\n",
      "\n",
      "\n",
      "----Statistics from one way ANOVA----\n",
      "F-Statistic: 370.5945085639539\n",
      "P-value: 1.1727179146691057e-155\n",
      "\n",
      "\n",
      "----Statistics from Kruskal-Wallis----\n",
      "H-Statistic: 715.7157547722887\n",
      "P-value: 3.839711067486734e-156\n"
     ]
    }
   ],
   "source": [
    "# Cross tabulation \n",
    "CrosstabResult=pd.crosstab(index=df_midwest['future trend from SSP 2'],columns=df_midwest['hh_income_by_taxRate'])\n",
    "print(CrosstabResult)\n",
    "# importing the required function\n",
    "from scipy.stats import chi2_contingency\n",
    "# Performing Chi-sq test\n",
    "ChiSqResult = chi2_contingency(CrosstabResult)\n",
    "# P-Value is the Probability of H0 being True\n",
    "# If P-Value&gt;0.05 then only we Accept the assumption(H0)\n",
    "print('The P-Value of the ChiSq Test is:', ChiSqResult[1])\n",
    "print('\\n')\n",
    "from scipy.stats import f_oneway\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(*[group['median_income'].values for name, group in df_midwest.groupby(\"future trend from SSP 2\")])\n",
    "# Print results\n",
    "print('----Statistics from one way ANOVA----')\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print('\\n')\n",
    "# Kuruskul Wallis Test\n",
    "from scipy.stats import kruskal\n",
    "#perform Kruskal-Wallis Test \n",
    "H_statistic, p_value = kruskal(*[group[\"median_income\"].values for name, group in df_midwest.groupby(\"future trend from SSP 2\")])\n",
    "print('----Statistics from Kruskal-Wallis----')\n",
    "print(\"H-Statistic:\", H_statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4ea8e-5f43-4f7a-8af4-65cc9329950c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
